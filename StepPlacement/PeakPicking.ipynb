{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "flexible-stuff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pending-louisiana",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path=\"D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np\"\n",
    "audio_path = os.listdir(root_path)\n",
    "audio_path = [ root_path+\"/\"+ad for ad in audio_path]\n",
    "\n",
    "root_path=\"D:/DeepLearning-workplace/taiko_generate/preprocessing/map_np\"\n",
    "map_path = os.listdir(root_path)\n",
    "map_path = [ root_path+\"/\"+mp for mp in map_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "coordinated-argentina",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151 151 17 17\n"
     ]
    }
   ],
   "source": [
    "t_audio_path = audio_path[:int(len(audio_path)*0.9)]\n",
    "t_map_path = map_path[:int(len(map_path)*0.9)]\n",
    "\n",
    "v_audio_path = audio_path[int(len(audio_path)*0.9):]\n",
    "v_map_path = map_path[int(len(map_path)*0.9):]\n",
    "\n",
    "print(len(t_audio_path),len(t_map_path),len(v_audio_path),len(v_map_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "manufactured-kazakhstan",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, MultiHeadAttention, LayerNormalization, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "prompt-collins",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "placement_model = keras.models.load_model(\"D:/DeepLearning-workplace/taiko_generate/model/StepPlacement100.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dress-birthday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/+.npy\n",
      "1 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1046137 BL-Records - Midway Colors.npy\n",
      "2 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1048173 red glasses - Schall we step.npy\n",
      "3 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1056704 Nekomata Master feat Tokiwa Yu - REcorrection (Cut Ver).npy\n",
      "4 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1059046 Neko Hacker - Kuishinbo Hacker feat Kuishinbo Akachan.npy\n",
      "5 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1068208 Kondo Koji - Frozen Hyrule.npy\n",
      "6 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1079752 Eve - Last Dance.npy\n",
      "7 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1079786 Camellia - Exit This Earth's Atomosphere (Camellia's PLANETARY__200STEP Remix).npy\n",
      "8 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1084028 goreshit - the pain of relief (we have our vices one and all).npy\n",
      "9 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1098381 t+pazolite vs P_Light - IZANA.npy\n",
      "10 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1099218 Masuda Junichi - Hanada City.npy\n",
      "11 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1102194 CORO MACHIKADO - YOIMACHI CANTARE (nenpulse bootleg remix).npy\n",
      "12 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1116903 COSIO(ZUNTATA) - FUJIN Rumble.npy\n",
      "13 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1122895 chelmico - Easy Breezy feat Zenpaku (dj-Jo Remix).npy\n",
      "14 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1127896 Voicians - Alive.npy\n",
      "15 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1128443 Run Girls, Run! - Share the light (TV Size).npy\n",
      "16 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1134649 pm04034 - Nonspeed.npy\n",
      "17 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1143435 fripSide - final phase (TV Size).npy\n",
      "18 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1160222 karoi - Konkon Kitsune.npy\n",
      "19 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1162493 Lena Raine - Pigstep.npy\n",
      "20 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1167103 Shimomura Yoko - Atarashii Bouken e!.npy\n",
      "21 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1167148 Yagi Yuki, Saeki Iori, Izawa Shiori, Itou Miku, Noguchi Yuri, Mizutani Marin - Shiny Happy Days (.npy\n",
      "22 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1167223 Imura Eriko - AND I BEGIN TO WONDER.npy\n",
      "23 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1170083 Akira Complex - Ether Strike.npy\n",
      "24 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1174299 Zekk - For Your Christmas.npy\n",
      "25 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1175776 Task Horizon - Flame Fetish.npy\n",
      "26 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1176081 t+pazolite - Chrome VOX.npy\n",
      "27 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1178559 MIMI - Toumeika.npy\n",
      "28 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1179815 t+pazolite - Tempestissimo.npy\n",
      "29 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1182359 Wiseman (CV_ Sayaka Harada & Akari Kito & Ayumi Mano) - Wiseman no Thema (TV Size).npy\n",
      "30 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1184151 MAO, Itou Miku, Tachibana Rika, Yuuki Aoi - SAI_KOU Start Dash.npy\n",
      "31 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1187506 THE ORAL CIGARETTES - Kyouran Hey Kids!!.npy\n",
      "32 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1188147 Tomoyuki Uchida - forever under construction.npy\n",
      "33 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1188578 Stray Kids - SLUMP -Japanese ver-.npy\n",
      "34 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1192577 Camellia - Towards The Horizon.npy\n",
      "35 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1194116 Nakiri Ayame - Deep Indigo.npy\n",
      "36 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1198443 Tokyo Machine - OKAY.npy\n",
      "37 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1200809 ChibaNyan vs Otogibara Era - GOMIKASU -Original Mix-.npy\n",
      "38 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1201538 toby fox - Can You Really Call This A Hotel I Didnt Receive A Mint On My Pillow Or Anything.npy\n",
      "39 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1207984 Poppin'Party - final phase.npy\n",
      "40 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1220994 Suzuki Konomi - Theater of Life (TV Size).npy\n",
      "41 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1224128 Block B - HER.npy\n",
      "42 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1228198 lapix - Carry Me Away (Extended Mix).npy\n",
      "43 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1232066 kemu feat orebananaP - Haikei Doppelganger.npy\n",
      "44 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1235438 Tokiwa Machi (CV_ Numakura Manami) - make a friendship (Cut Ver).npy\n",
      "45 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1236400 Momo Belia Deviluke (CV_ Toyosaki Aki) - MORE & MORE.npy\n",
      "46 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1240233 ARForest - Metheus.npy\n",
      "47 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1241825 ARForest - Hemisphere.npy\n",
      "48 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1242468 loveaddictspropylhexedrineoverdose - only toying with me.npy\n",
      "49 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1243513 Hanabasami Kyo - Charles (Arrange ver) (Cut Ver).npy\n",
      "50 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1243675 Eve - Dramaturgy.npy\n",
      "51 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1247020 Tanchiky - ENERGY SYNERGY MATRIX.npy\n",
      "52 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1248836 Cartoon - Why We Lose (feat Coleman Trapp) (Cut Ver).npy\n",
      "53 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1251921 Suzuki Keiichi, Tanaka Hirokazu - A Flash of Memory.npy\n",
      "54 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1255970 Hana to Onyx - Ariadne.npy\n",
      "55 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1257656 goreshit - too young to love.npy\n",
      "56 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1260310 Usada Pekora - Discommunication Alien.npy\n",
      "57 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1262793 Nekomata Okayu - flos.npy\n",
      "58 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1264028 Hoshimachi Suisei with Hololive Fantasy - Saga Jihen.npy\n",
      "59 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1265229 Iglooghost - Clear Tamei.npy\n",
      "60 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1265617 Yasui Yousuke - YO-KAI Disco.npy\n",
      "61 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1267305 Petit Rabbit's - Tenkuu Cafeteria (TV Size).npy\n",
      "62 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1268517 Umeboshi Chazuke - Run_2 Run To You!!.npy\n",
      "63 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1271715 Iguchi Yuka - over and over (TV Size).npy\n",
      "64 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1274162 Hikasa Youko, Uchida Maaya, Taketatsu Ayana, Akesaka Satomi - Gokujo no Jouken (TV Size).npy\n",
      "65 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1274440 Camellia feat Nanahira - Amor De Verao.npy\n",
      "66 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1274884 Omoi - Snow Drive (0123).npy\n",
      "67 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1274930 Omoi - Nee William.npy\n",
      "68 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1275050 Yumeko - Soitogeta Android e.npy\n",
      "69 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1275058 UNDEAD CORPORATION - Under the scarlet sky pt 3.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1275784 ARForest - Journey.npy\n",
      "71 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1276230 Triodust - FINALE.npy\n",
      "72 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1276509 ARForest - The Last Page.npy\n",
      "73 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1278498 Sable Hills - No Love Lost.npy\n",
      "74 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1282473 LiSA - ROCK-mode (Cut Ver).npy\n",
      "75 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1282787 Houshou Marine - Ahoy!! Warera Houshou Kaizokudan_.npy\n",
      "76 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1283761 AZKi - FakeFakeFake.npy\n",
      "77 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1285524 3R2 - Adventure Starts Here.npy\n",
      "78 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1286973 Eyemedia - Bloody Purity.npy\n",
      "79 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1287105 Kyaai - ensolarado.npy\n",
      "80 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1287218 Daft Punk - Contact (Cut Ver).npy\n",
      "81 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1289196 Nekrogoblikon - Powercore.npy\n",
      "82 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1289460 Satou Hitomi - Dark Trinity no Thema.npy\n",
      "83 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1289473 sakuraburst - deconstructing nature.npy\n",
      "84 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1290952 tomatomerde - Brave Shine.npy\n",
      "85 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1291324 Toby Fox - Checker Dance.npy\n",
      "86 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1291429 Joe Hisaishi - One Summer's Day (Closed on Sunday Remix).npy\n",
      "87 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1292111 Sugimori Masakazu - Tsuikyuu _ Oitsumerarete.npy\n",
      "88 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1292718 cute girls doing cute things - Ideal.npy\n",
      "89 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1294869 Morimori Atsushi - Alter Ego.npy\n",
      "90 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1296713 BLACKPINK - BOOMBAYAH.npy\n",
      "91 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1298160 Himesaka Noa (CV_ Kito Akari) - Atashi Kawaii Sengen!!! (nenpulse bootleg remix).npy\n",
      "92 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1298908 Natori Sana - Sana no Outa (Angeart J-Core Edit).npy\n",
      "93 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1299326 fiend - Morrissey.npy\n",
      "94 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1302274 Se-U-Ra - Hope 4 Hopeful.npy\n",
      "95 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1303113 KyoKa - Ouran Romancia.npy\n",
      "96 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1303887 REDALiCE feat Usada Pekora & Sakura Miko - Peko Miko Daisensou!!.npy\n",
      "97 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1305819 Se-U-Ra - Cris Fortress.npy\n",
      "98 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1307689 K2HAmu - Pekorap3D Remix.npy\n",
      "99 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1309846 Rin - Lunatic set 02 _ Usagi wa Maiorita.npy\n",
      "100 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1310156 toby fox - Snowdin Town.npy\n",
      "101 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1311932 Sewerslvt - inlove.npy\n",
      "102 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1313012 Kageyama Shouta - N no Dragon.npy\n",
      "103 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1315115 SOPHIE - LEMONADE.npy\n",
      "104 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1315809 Se-U-Ra - Afterwars -Infection-.npy\n",
      "105 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1316175 PSYQUI - Hype feat Such (lapix Remix).npy\n",
      "106 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1316609 Morimori Atsushi vs uma - Sweet_ Witch_ Girl_.npy\n",
      "107 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1316773 TUYU - Doro no Bunzai de Watashi dake no Taisetsu o Ubaouda nante.npy\n",
      "108 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1317050 Parry Gripp - I Wanna Guinea Pig For Christmas.npy\n",
      "109 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1318825 SECONDWALL - Light.npy\n",
      "110 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1320872 MYUKKE - The 89's Momentum.npy\n",
      "111 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1322775 Numakura Manami - Climber's High! (TV Size).npy\n",
      "112 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1323774 URBANGARDE - BAERUNA.npy\n",
      "113 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1323985 TUYU - Kako ni Torawarete Iru.npy\n",
      "114 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1325757 Ohta Asuka, Nagamatsu Ryo - Wario Kouzan.npy\n",
      "115 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1326923 Lime - 8bit Voyager.npy\n",
      "116 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1327030 toby fox - Bergentrueckung.npy\n",
      "117 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1327059 Amon Amarth - Shield Wall.npy\n",
      "118 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1328018 Kobaryo - Transceiver FX.npy\n",
      "119 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1328323 NIWASHI - Playing with Ruby.npy\n",
      "120 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1329682 Murasaki Shion - KING.npy\n",
      "121 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1329875 hololive IDOL PROJECT - BLUE CLAPPER.npy\n",
      "122 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1330627 EDOGA-SULLIVAN - WONDERFUL WONDER (TV Size).npy\n",
      "123 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1331332 Camellia - Xeroa.npy\n",
      "124 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1331746 orangentle - Papyrus (ARCADE SUITE).npy\n",
      "125 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1332550 Fractal Dreamers - Whispers from a Distant Star.npy\n",
      "126 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1332612 M2U - Felis.npy\n",
      "127 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1336533 Houshou Marine with Holoism Fantasy - Hoihoi_Gensou Holoism.npy\n",
      "128 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1336669 cute girls doing cute things - Let's Go!.npy\n",
      "129 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1336717 Jun Kuroda - u'n me.npy\n",
      "130 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1336877 ChouCho - Yasashisa no Riyuu.npy\n",
      "131 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1337389 cute girls doing cute things - Main Heroine.npy\n",
      "132 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1337543 MYUKKE - FULi AUTO BUSTER.npy\n",
      "133 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1338121 Jun Kuroda - Meikyoshisui.npy\n",
      "134 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1338901 kanone - Infinite Galaxy.npy\n",
      "135 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1339071 Ohta Asuka, Nagamatsu Ryo - Kara Kara Iseki (Cut Ver).npy\n",
      "136 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1342315 Yu-Peng Chen @HOYO-MiX - A Sweet Smile.npy\n",
      "137 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1345190 MYUKKE - ROAD to 773H.npy\n",
      "138 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1345449 Masuda Junichi - Sentou! Densetsu no Pokemon.npy\n",
      "139 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1345815 Masahiro Godspeed Aoki - Blaze.npy\n",
      "140 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1346268 Akiyama Uni feat JUN - Chitei ni Saku Bara.npy\n",
      "141 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1347803 Joji - Gimme Love (Cut Ver).npy\n",
      "142 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1349645 Nekomata Master vs HuMeR - BUZRA.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1350798 Toby Fox - dogcheck.npy\n",
      "144 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1354866 Jake Kaufman - The Nightmare Woods (Run Run Rottytops!).npy\n",
      "145 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1361550 Jake Kaufman - The Spin Controller.npy\n",
      "146 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1363369 Kito Akari - Kimi no Tonari de (TV Size).npy\n",
      "147 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1363594 Sasaki Sayaka - Love's Oracle.npy\n",
      "148 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1371469 glaive - astrid.npy\n",
      "149 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1391235 fhana - Kimi to Iu Tokuiten [singular you].npy\n",
      "150 D:/DeepLearning-workplace/taiko_generate/preprocessing/audio_np/1396458 tiku sens - fly a rocket to the center of your heart.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-c0dc1371ea54>:26: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  train_x=np.array(train_x)\n",
      "<ipython-input-6-c0dc1371ea54>:27: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  train_y=np.array(train_y)\n"
     ]
    }
   ],
   "source": [
    "train_x=[]\n",
    "train_y=[]\n",
    "for i in range(len(t_audio_path)):\n",
    "    print(i,t_audio_path[i])\n",
    "    audio = np.load(t_audio_path[i])\n",
    "    f = open(t_map_path[i], \"r\") #讀所有的map\n",
    "    maps = json.load(f)\n",
    "    f.close()\n",
    "    \n",
    "    for key in maps.keys():        \n",
    "        dif = np.zeros(shape=(audio.shape[0],5))\n",
    "        dif[:,int(key)]=1\n",
    "        rst = placement_model.predict([audio, dif]) #原先模型預測結果\n",
    "        \n",
    "        x = np.zeros(shape=(audio.shape[0],6)) #建立x值\n",
    "        x[:,int(key)+1]=1\n",
    "        for ind in range(len(rst)):\n",
    "            x[ind][0]=rst[ind]\n",
    "        train_x.append(x)\n",
    "        \n",
    "        y=np.zeros(audio.shape[0])\n",
    "        for timing, _ in maps[key]:\n",
    "            y[timing-8]=1\n",
    "        train_y.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "interior-temperature",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(611,) (611,)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape,train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-standing",
   "metadata": {},
   "outputs": [],
   "source": [
    "length=[]\n",
    "for d in train_x:\n",
    "    length.append(len(d))\n",
    "max_len = max(length)\n",
    "\n",
    "train_X = np.zeros((len(train_x),max_len,6),dtype='float32')\n",
    "train_Y = np.zeros((len(train_y),max_len,1),dtype='float32')\n",
    "\n",
    "for i, tx in enumerate(train_x):\n",
    "    for j, d in enumerate(tx):\n",
    "        train_X[i, j]=d\n",
    "    for j, d in enumerate(train_y[i]):\n",
    "        train_Y[i, j]=d\n",
    "        \n",
    "np.save(\"D:/DeepLearning-workplace/taiko_generate/StepPlacement/PeakPicking_X\", train_X)\n",
    "np.save(\"D:/DeepLearning-workplace/taiko_generate/StepPlacement/PeakPicking_Y\", train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specified-aviation",
   "metadata": {},
   "source": [
    "## 分隔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "suffering-fruit",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X=np.load(\"D:/DeepLearning-workplace/taiko_generate/StepPlacement/PeakPicking_X.npy\")\n",
    "train_Y=np.load(\"D:/DeepLearning-workplace/taiko_generate/StepPlacement/PeakPicking_Y.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "certain-subscriber",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, MultiHeadAttention, LayerNormalization, Dense\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "accurate-grenada",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=Input(shape=(None,6))\n",
    "layer = MultiHeadAttention(num_heads=2, key_dim=2)\n",
    "x = layer(inputs, inputs)\n",
    "x = LayerNormalization(epsilon=1e-6)(x)\n",
    "outputs = Dense(1,activation='sigmoid')(x)\n",
    "model=Model(inputs,outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "experimental-macro",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = ModelCheckpoint(\n",
    "    'D:/DeepLearning-workplace/taiko_generate/StepPlacement/model_checkpoints/peak_model{epoch:03d}-loss{loss:.3f}.h5', \n",
    "    monitor='loss', \n",
    "    save_best_only=True, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "competitive-blake",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, None, 6)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_7 (MultiHe (None, None, 6)      114         input_5[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_7 (LayerNor (None, None, 6)      12          multi_head_attention_7[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, None, 1)      7           layer_normalization_7[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 133\n",
      "Trainable params: 133\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='sgd',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "solid-cancellation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[1,2,41093,41093] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model_4/multi_head_attention_7/dropout/dropout/random_uniform/RandomUniform (defined at <ipython-input-28-8a4db4cf26c7>:1) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_7272]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-8a4db4cf26c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history = model.fit(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtrain_Y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    886\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 888\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    889\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[1,2,41093,41093] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model_4/multi_head_attention_7/dropout/dropout/random_uniform/RandomUniform (defined at <ipython-input-28-8a4db4cf26c7>:1) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_7272]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_X,\n",
    "    train_Y,\n",
    "    batch_size=1,\n",
    "    epochs=100,\n",
    "    callbacks=[mc]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stylish-reception",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"D:/DeepLearning-workplace/taiko_generate/model/PeakPicking100.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-oracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_history(history, fn):\n",
    "    with open(fn, 'wb') as fw:\n",
    "        pickle.dump(history.history, fw, protocol=2)\n",
    "save_history(history,\"D:/DeepLearning-workplace/taiko_generate/StepPlacement/pickpicking_history.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binding-curtis",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-supplier",
   "metadata": {},
   "outputs": [],
   "source": [
    "F_measure_list=[]\n",
    "for i,ap in enumerate(v_audio_path):\n",
    "    audio=np.load(ap)\n",
    "    f = open(v_map_path[i], \"r\") #讀所有的map\n",
    "    maps = json.load(f)\n",
    "    f.close()\n",
    "    \n",
    "    for key in maps.keys():\n",
    "        \n",
    "        dif = np.zeros(shape=(audio.shape[0],5))\n",
    "        dif[:,int(key)]=1\n",
    "        result = model.predict([audio, dif])\n",
    "\n",
    "        data = []\n",
    "        for r in result:\n",
    "            data.append(r[0])\n",
    "        data=np.array(data)\n",
    "\n",
    "        data = data*1000\n",
    "        data = data.astype(int)\n",
    "\n",
    "        win = signal.windows.hamming(50)\n",
    "        x = signal.convolve(data,win,mode='same')/sum(win)\n",
    "\n",
    "        peaks, _ = signal.find_peaks(x, prominence=6-int(key))\n",
    "        \n",
    "        \n",
    "        \n",
    "        # 取出實際map之節拍毫秒值\n",
    "        realMiliSecs = list()\n",
    "        for ele in maps[key]:\n",
    "            realMiliSecs.append(ele[0])\n",
    "\n",
    "        # 誤差區間值\n",
    "        DET_RANGE = 10\n",
    "        # 計算TP, FP, FN score以得出精準度\n",
    "        tpScore, fpScore, fnScore, previousRealMiliSecs, hitFlag = 0, 0, 0, 0, False\n",
    "        for guessMiliSecs in peaks:\n",
    "            # 取得與猜測時間點最近的實際時間點\n",
    "            closestRealMiliSecs = min(realMiliSecs, key = lambda x:abs(x-guessMiliSecs))\n",
    "            if previousRealMiliSecs != closestRealMiliSecs:\n",
    "                if not hitFlag:\n",
    "                    fnScore += 1\n",
    "                hitFlag = False\n",
    "            #print([closestRealMiliSecs, guessMiliSecs])\n",
    "            if (closestRealMiliSecs - 8) + DET_RANGE > guessMiliSecs > (closestRealMiliSecs - 8) - DET_RANGE:\n",
    "                #print('hit')\n",
    "                tpScore += 1\n",
    "                hitFlag = True\n",
    "            else:\n",
    "                fpScore += 1\n",
    "            previousRealMiliSecs = closestRealMiliSecs\n",
    "\n",
    "        F_measure = 2 * tpScore / (2 * tpScore + fpScore + fnScore)\n",
    "        F_measure_list.append(F_measure)\n",
    "        print(F_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "every-covering",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-necessity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-watson",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
